library(rpart)
library(rpart.plot)
library(caret)
load("data/College4.RData")
head(College4)
unis$Tipo<-factor(College4$Private=="Yes",labels=c('Pública','Privada'))
head(unis)
table(unis$Tipo)
set.seed(40)
nobs<-nrow(unis)
itrain<-sample(nobs,0.8*nobs)
train<-unis[itrain,]
test<-unis[-itrain,]
unis<-College4[,colnames(College4)!="Private"]
unis$Tipo<-factor(College4$Private=="Yes",labels=c('Pública','Privada'))
head(unis)
table(unis$Tipo)
set.seed(40)
nobs<-nrow(unis)
itrain<-sample(nobs,0.8*nobs)
train<-unis[itrain,]
test<-unis[-itrain,]
library(kernlab)
set.seed(40)
svm<-ksvm(Tipo~.,data=train)
svm #Param C = 1; Sigma = 0.05438
pred<-predict(svm,newdata=test)
caret::confusionMatrix(pred,test$Tipo)
tune.grid<-expand.grid(sigma=c(0.01,0.05,0.1),C=c(0.5,1,10),error=NA)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)){
fit<-ksvm(Tipo~.,data=train[,],cross=10,C=tune.grid$C[i],kpar=list(tune.grid$sigma[i]))
fit.error<-fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i, ]
}
}
final.model # Param. C = 0.5; sigma = 0.01
pred2<-predict(final.model,newdata=test)
caret::confusionMatrix(pred2,test$Tipo)
head(predict(svm,newdata = test))
head(predict(svm,newdata = test,type="class"))
head(predict(svm,newdata = test))
head(predict(final.model,newdata = test))
head(predict(final.model,newdata = test,type="prob"))
head(predict(svm,newdata = test,type="prob"))
p.est.1<-predict(svm,newdata = test, type = "probabilities")
svm<-ksvm(Tipo~.,data=train,prob.model=TRUE)
svm #Param C = 1; Sigma = 0.05438
p.est.1<-predict(svm,newdata = test, type = "probabilities")
head(p.est.1)
tune.grid<-expand.grid(sigma=c(0.01,0.05,0.1),C=c(0.5,1,10),error=NA)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)){
fit<-ksvm(Tipo~.,prob.model=TRUE,data=train[,],cross=10,C=tune.grid$C[i],kpar=list(tune.grid$sigma[i]))
fit.error<-fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i, ]
}
}
p.est.2<-predict(final.model,newdata = test, type = "probabilities")
head(p.est.2)
cbind(p.est.1,p.est.2)
head(cbind(p.est.1,p.est.2))
?confusionMatrix
# Predicción con el modelo del apartado b) (C=0.05, sigma = 0.01):
caret::confusionMatrix(pred2,test$Tipo)
# Librerías
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)}
# Librerías
packages <- c("rpart", "rpart.plot", "caret", "randomForest", "pdp", "kernlab")
ipak(packages)
# Datos
load("data/College4.RData")
head(College4, n = 3)
dim(College4)
datos <- College4[,-1]
datos$Tipo <- factor(College4$Private == "Yes", labels = c("Pública", "Privada"))
head(datos,n = 3)
#Proporción privada-pública
table(datos$Tipo)
#Semilla
set.seed(40)
nobs <- nrow(datos) #Filas
itrain <- sample(nobs, 0.8 * nobs)
train <- datos[itrain, ] # M. Entrenamiento
test <- datos[-itrain, ] # M. Test
tree<-rpart(Tipo~.,data=train)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
tree <- rpart(Tipo ~ ., data = train, cp = 0)
plotcp(tree)
xerror <- tree$cptable[,"xerror"]
imin.xerror <- which.min(xerror)
upper.xerror <- xerror[imin.xerror] + tree$cptable[imin.xerror, "xstd"]
icp <- min(which(xerror <= upper.xerror))
cp <- tree$cptable[icp, "CP"]
cp
tree<-prune(tree,cp=cp)
rpart.plot(tree,
extra = 104,          # show fitted class, probs, percentages
box.palette = "GnBu", # color scheme
branch.lty = 3,       # dotted branch lines
shadow.col = "gray",  # shadows under the node boxes
main="Árbol de clasificación privada-pública",
nn = TRUE)
obs <- test$Tipo # Observaciones
pred <- predict(tree, newdata = test, type = "class") #Predicciones
confusionMatrix(pred,obs)
pred_prob <- predict(tree, newdata = test) #Estimaciones de la probabilidad
head(pred_prob)
set.seed(40)
tuneGrid <- data.frame(mtry = c(1, 2, 4, 6))
rf.caret <-
train(
Tipo ~ .,
data = train,
method = "rf",
ntree = 300,
tuneGrid = tuneGrid,
trControl = trainControl(
method = "cv",
number = 10,
selectionFunction = "oneSE"
)
)
final <- rf.caret$finalModel;final
plot(final, main = "Tasas de error OOB")
legend("topright",
colnames(final$err.rate),
lty = 1:5,
col = 1:6)
importance(final)
varImpPlot(final)
pdp1 <- partial(final, "Outstate", train = train)
p1 <- plotPartial(pdp1)
pdp2 <- partial(final, "Enroll", train = train)
p2 <- plotPartial(pdp2)
grid.arrange(p1, p2, ncol = 2)
obs <- test$Tipo
head(predict(final, newdata = test))
pred <- predict(final, newdata = test, type = "class")
table(obs, pred)
confusionMatrix(pred, obs)
set.seed(40)
svm <- ksvm(Tipo ~ ., data = train,prob.model=TRUE)
svm
dim(train)
pred <- predict(svm, newdata = test)
tune.grid <- expand.grid(
sigma = c(0.01, 0.05, 0.1),
C = c(0.5, 1, 10),
error = NA
)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)) {
fit <-
ksvm(
Tipo ~ .,
prob.model=TRUE,
data = train[, ],
cross = 10,
C = tune.grid$C[i],
kpar = list(tune.grid$sigma[i])
)
fit.error <- fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i,]
}
}
best.tune
final.model
pred2 <- predict(final.model, newdata = test)
# Predicción con el modelo por defecto (C = 1, sigma = 0.05438):
caret::confusionMatrix(pred, test$Tipo)
# Predicción con el modelo del apartado b) (C=0.05, sigma = 0.01):
caret::confusionMatrix(pred2,test$Tipo)
table(obs,pred)
#Comprobación de las probabilidades del primer modelo (por defecto):
p.est.1<-predict(svm,newdata = test, type = "probabilities")
head(p.est.1)
#Comprobación de las probabilidades del segundo modelo (apartado b):
p.est.2<-predict(final.model,newdata = test, type = "probabilities")
head(p.est.2)
?confusionMatrix
library(rpart)
library(rpart.plot)
library(caret)
load("data/College4.RData")
head(College4)
unis<-College4[,colnames(College4)!="Private"]
unis$Tipo<-factor(College4$Private=="Yes",labels=c('Pública','Privada'))
head(unis)
table(unis$Tipo)
set.seed(40)
nobs<-nrow(unis)
itrain<-sample(nobs,0.8*nobs)
train<-unis[itrain,]
test<-unis[-itrain,]
tree<-rpart(Tipo~.,data=train)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Selección paramétro
rpart.rules(tree,style="tall")
tree<-rpart(Tipo~.,data=train,cp=0)
plotcp(tree)
xerror<-tree$cptable[,"xerror"]
imin.xerror<-which.min(xerror)
upper.xerror<-xerror[imin.xerror]+tree$cptable[imin.xerror,"xstd"]
icp<-min(which(xerror<=upper.xerror))
cp<-tree$cptable[icp,"CP"]
tree<-prune(tree,cp=cp)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Predicciones
obs<-test$Tipo
head(predict(tree,newdata = test))
pred<-predict(tree,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 2
#Apartado a y b
tuneGrid<-data.frame(mtry=c(1,2,4,6))
rf.caret<-train(Tipo~.,data=train,method="rf",ntree=300, tuneGrid = tuneGrid,
trControl=trainControl(method="cv",number = 10,selectionFunction = "oneSE"))
final<-rf.caret$finalModel
plot(final,main="Tasas de error OOB")
legend("topright",colnames(final$err.rate),lty=1:5,col=1:6)
#Apartado c
library(randomForest)
importance(final)
varImpPlot(final)
library(pdp)
pdp1<-partial(final,"Outstate",train=train)
p1<-plotPartial(pdp1)
pdp2<-partial(final,"Enroll",train=train)
p2<-plotPartial(pdp2)
grid.arrange(p1,p2,ncol=2)
######Falta con la librería vivi
#Apartado d)
obs<-test$Tipo
head(predict(final,newdata = test))
pred<-predict(final,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 3
#Apartado a)
library(kernlab)
set.seed(40)
svm<-ksvm(Tipo~.,data=train,prob.model=TRUE)
svm #Param C = 1; Sigma = 0.05438
pred<-predict(svm,newdata=test)
caret::confusionMatrix(pred,test$Tipo)
#Comprobación de las probabilidades
p.est.1<-predict(svm,newdata = test, type = "probabilities")
head(p.est.1)
#Apartado b)
tune.grid<-expand.grid(sigma=c(0.01,0.05,0.1),C=c(0.5,1,10),error=NA)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)){
fit<-ksvm(Tipo~.,prob.model=TRUE,data=train[,],cross=10,C=tune.grid$C[i],kpar=list(tune.grid$sigma[i]))
fit.error<-fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i, ]
}
}
final.model # Param. C = 0.5; sigma = 0.01
pred2<-predict(final.model,newdata=test)
caret::confusionMatrix(pred2,test$Tipo)
#Comprobación de las probabilidades
p.est.2<-predict(final.model,newdata = test, type = "probabilities")
head(p.est.2)
#Comparación importancia
importance(svm)
#Comparación importancia
importance(final.model)
?ksvm
#Comprobación de las probabilidades
p.est.1<-predict(svm,newdata = test, type = "probabilities",importance=TRUE)
?vivi
??vivi
#Comparación importancia
library(rminer)
#Comparación importancia
library(rminer)
Importance(final.model)
Importance(final.model,data=test)
#Comparación importancia
library(vivid)
library(vip)
library(vip)
?vip
?vivid
??vivid
library(rpart)
library(rpart.plot)
library(caret)
load("data/College4.RData")
head(College4)
unis<-College4[,colnames(College4)!="Private"]
unis$Tipo<-factor(College4$Private=="Yes",labels=c('Pública','Privada'))
head(unis)
table(unis$Tipo)
set.seed(40)
nobs<-nrow(unis)
itrain<-sample(nobs,0.8*nobs)
train<-unis[itrain,]
test<-unis[-itrain,]
tree<-rpart(Tipo~.,data=train)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Selección paramétro
rpart.rules(tree,style="tall")
tree<-rpart(Tipo~.,data=train,cp=0)
plotcp(tree)
xerror<-tree$cptable[,"xerror"]
imin.xerror<-which.min(xerror)
upper.xerror<-xerror[imin.xerror]+tree$cptable[imin.xerror,"xstd"]
icp<-min(which(xerror<=upper.xerror))
cp<-tree$cptable[icp,"CP"]
tree<-prune(tree,cp=cp)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Predicciones
obs<-test$Tipo
head(predict(tree,newdata = test))
pred<-predict(tree,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 2
#Apartado a y b
tuneGrid<-data.frame(mtry=c(1,2,4,6))
rf.caret<-train(Tipo~.,data=train,method="rf",ntree=300, tuneGrid = tuneGrid,
trControl=trainControl(method="cv",number = 10,selectionFunction = "oneSE"))
final<-rf.caret$finalModel
plot(final,main="Tasas de error OOB")
legend("topright",colnames(final$err.rate),lty=1:5,col=1:6)
#Apartado c
library(randomForest)
importance(final)
varImpPlot(final)
library(pdp)
pdp1<-partial(final,"Outstate",train=train)
p1<-plotPartial(pdp1)
pdp2<-partial(final,"Enroll",train=train)
p2<-plotPartial(pdp2)
grid.arrange(p1,p2,ncol=2)
######Falta con la librería vivi
#Apartado d)
obs<-test$Tipo
head(predict(final,newdata = test))
pred<-predict(final,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 3
#Apartado a)
library(kernlab)
set.seed(40)
svm<-ksvm(Tipo~.,data=train,prob.model=TRUE)
svm #Param C = 1; Sigma = 0.05438
pred<-predict(svm,newdata=test)
caret::confusionMatrix(pred,test$Tipo)
#Comprobación de las probabilidades
p.est.1<-predict(svm,newdata = test, type = "probabilities")
head(p.est.1)
#Apartado b)
tune.grid<-expand.grid(sigma=c(0.01,0.05,0.1),C=c(0.5,1,10),error=NA)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)){
fit<-ksvm(Tipo~.,prob.model=TRUE,data=train[,],cross=10,C=tune.grid$C[i],kpar=list(tune.grid$sigma[i]))
fit.error<-fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i, ]
}
}
final.model # Param. C = 0.5; sigma = 0.01
pred2<-predict(final.model,newdata=test)
caret::confusionMatrix(pred2,test$Tipo)
#Comprobación de las probabilidades
p.est.2<-predict(final.model,newdata = test, type = "probabilities")
head(p.est.2)
library(rpart)
library(rpart.plot)
library(caret)
load("data/College4.RData")
head(College4)
unis<-College4[,colnames(College4)!="Private"]
unis$Tipo<-factor(College4$Private=="Yes",labels=c('Pública','Privada'))
head(unis)
table(unis$Tipo)
set.seed(40)
nobs<-nrow(unis)
itrain<-sample(nobs,0.8*nobs)
train<-unis[itrain,]
test<-unis[-itrain,]
tree<-rpart(Tipo~.,data=train)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Selección paramétro
rpart.rules(tree,style="tall")
tree<-rpart(Tipo~.,data=train,cp=0)
plotcp(tree)
xerror<-tree$cptable[,"xerror"]
imin.xerror<-which.min(xerror)
upper.xerror<-xerror[imin.xerror]+tree$cptable[imin.xerror,"xstd"]
icp<-min(which(xerror<=upper.xerror))
cp<-tree$cptable[icp,"CP"]
tree<-prune(tree,cp=cp)
rpart.plot(tree,main="Árbol de clasificación privada-pública")
#Predicciones
obs<-test$Tipo
head(predict(tree,newdata = test))
pred<-predict(tree,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 2
#Apartado a y b
tuneGrid<-data.frame(mtry=c(1,2,4,6))
rf.caret<-train(Tipo~.,data=train,method="rf",ntree=300, tuneGrid = tuneGrid,
trControl=trainControl(method="cv",number = 10,selectionFunction = "oneSE"))
final<-rf.caret$finalModel
plot(final,main="Tasas de error OOB")
legend("topright",colnames(final$err.rate),lty=1:5,col=1:6)
#Apartado c
library(randomForest)
importance(final)
varImpPlot(final)
library(pdp)
pdp1<-partial(final,"Outstate",train=train)
p1<-plotPartial(pdp1)
pdp2<-partial(final,"Enroll",train=train)
p2<-plotPartial(pdp2)
grid.arrange(p1,p2,ncol=2)
######Falta con la librería vivi
#Apartado d)
obs<-test$Tipo
head(predict(final,newdata = test))
pred<-predict(final,newdata=test,type="class")
table(obs,pred)
caret::confusionMatrix(pred,obs)
#Ejercicio 3
#Apartado a)
library(kernlab)
set.seed(40)
svm<-ksvm(Tipo~.,data=train,prob.model=TRUE)
svm #Param C = 1; Sigma = 0.05438
pred<-predict(svm,newdata=test)
caret::confusionMatrix(pred,test$Tipo)
#Comprobación de las probabilidades
p.est.1<-predict(svm,newdata = test, type = "probabilities")
head(p.est.1)
#Apartado b)
tune.grid<-expand.grid(sigma=c(0.01,0.05,0.1),C=c(0.5,1,10),error=NA)
best.err <- Inf
set.seed(40)
for (i in 1:nrow(tune.grid)){
fit<-ksvm(Tipo~.,prob.model=TRUE,data=train[,],cross=10,C=tune.grid$C[i],kpar=list(tune.grid$sigma[i]))
fit.error<-fit@cross
tune.grid$error[i] <- fit.error
if (fit.error < best.err) {
final.model <- fit
best.err <- fit.error
best.tune <- tune.grid[i, ]
}
}
final.model # Param. C = 0.5; sigma = 0.01
pred2<-predict(final.model,newdata=test)
caret::confusionMatrix(pred2,test$Tipo)
#Comprobación de las probabilidades
p.est.2<-predict(final.model,newdata = test, type = "probabilities")
head(p.est.2)
?vivi
??vivi
#Comparación importancia
library(vivid)
?vivi
fit_rf  <- vivi(data = test, fit = final.model, response = "Tipo", importanceType = "%IncMSE")
fit_rf
viviHeatmap(mat=fit_rf)
viviHeatmap(mat=fit_rf[1:5,1:5])
?viviHeatmap
